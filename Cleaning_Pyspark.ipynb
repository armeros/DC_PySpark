{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cleaning_Pyspark.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zo2kPMOo8FtO",
        "outputId": "b180b578-c34b-404f-9493-bdaf662d2620"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n",
            "\u001b[K     |████████████████████████████████| 204.2MB 67kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612242 sha256=5b1c483f64e15496cf4d154279a0ef3c119c959348b275eb8a10266e0a7371ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kep0j1wk8L9t"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark import SparkContext\r\n",
        "sc = SparkContext()\r\n",
        "spark = SparkSession.builder.getOrCreate()\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "78gxmFR7JUS3",
        "outputId": "1a63ca00-90e2-4a38-fafa-d24878330e63"
      },
      "source": [
        "display(spark.read.csv(\"DallasCouncilVoters.csv.gz\", inferSchema=True, header=True).show(4))\r\n",
        "display(spark.read.csv(\"DallasCouncilVotes.csv.gz\", inferSchema=True, header=True).show(4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+\n",
            "|      DATE|        TITLE|         VOTER_NAME|\n",
            "+----------+-------------+-------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|\n",
            "+----------+-------------+-------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+\n",
            "|      DATE|AGENDA_ITEM_NUMBER|ITEM_TYPE|DISTRICT|        TITLE|         VOTER NAME|VOTE CAST|FINAL ACTION TAKEN|AGENDA ITEM DESCRIPTION|         AGENDA_ID|             VOTE_ID|\n",
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+\n",
            "|02/08/2017|                 1|   AGENDA|      13|Councilmember|  Jennifer S. Gates|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|\n",
            "|02/08/2017|                 1|   AGENDA|      14|Councilmember| Philip T. Kingston|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|\n",
            "|02/08/2017|                 1|   AGENDA|      15|        Mayor|Michael S. Rawlings|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|\n",
            "|02/08/2017|                 1|   AGENDA|       2|Councilmember|       Adam Medrano|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__1_2|\n",
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXWaWogw972r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "9b17ee3c-506e-47dd-fc25-d365c95bbf68"
      },
      "source": [
        "# StructField(\"name\", dtype, nullable=True)\r\n",
        "peopleSchema = StructType([StructField(\"name\", StringType(), True ), StructField(\"age\", IntegerType(), True), StructField(\"city\", StringType(), True)])\r\n",
        "people_df = spark.read.format(\"csv\").load(name=\"voterdata.csv\", schema=peopleSchema) # อันนี้ใส่ Schema มั่วๆเอา\r\n",
        "\r\n",
        "# Read csv\r\n",
        "sdf = spark.read.csv(\"voterdata.csv\", inferSchema=True, header=True)\r\n",
        "\r\n",
        "print(\"Check Schema: Notice that the column 'AGENDA_ITEM_NUMBER' is string.\")\r\n",
        "display(sdf.printSchema()); print(\"\\n\")\r\n",
        "\r\n",
        "# Change AGENDA_ITEM_NUMBER into integer\r\n",
        "sdf = sdf.withColumn(\"AGENDA_ITEM_NUMBER\", sdf[\"AGENDA_ITEM_NUMBER\"].cast(\"integer\"))\r\n",
        "\r\n",
        "# Add column\r\n",
        "sdf = sdf.withColumn(\"ITEM+100\", sdf[\"AGENDA_ITEM_NUMBER\"]+100)\r\n",
        "display(sdf.show(3))\r\n",
        "\r\n",
        "# Drop column\r\n",
        "sdf = sdf.drop(sdf[\"AGENDA_ITEM_NUMBER\"])\r\n",
        "display(sdf.show(3))\r\n",
        "\r\n",
        "# Count number rows\r\n",
        "display(sdf.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check Schema: Notice that the column 'AGENDA_ITEM_NUMBER' is string.\n",
            "root\n",
            " |-- DATE: string (nullable = true)\n",
            " |-- AGENDA_ITEM_NUMBER: string (nullable = true)\n",
            " |-- ITEM_TYPE: string (nullable = true)\n",
            " |-- DISTRICT: integer (nullable = true)\n",
            " |-- TITLE: string (nullable = true)\n",
            " |-- VOTER NAME: string (nullable = true)\n",
            " |-- VOTE CAST: string (nullable = true)\n",
            " |-- FINAL ACTION TAKEN: string (nullable = true)\n",
            " |-- AGENDA ITEM DESCRIPTION: string (nullable = true)\n",
            " |-- AGENDA_ID: string (nullable = true)\n",
            " |-- VOTE_ID: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "|      DATE|AGENDA_ITEM_NUMBER|ITEM_TYPE|DISTRICT|        TITLE|         VOTER NAME|VOTE CAST|FINAL ACTION TAKEN|AGENDA ITEM DESCRIPTION|         AGENDA_ID|             VOTE_ID|ITEM+100|\n",
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "|02/08/2017|                 1|   AGENDA|      13|Councilmember|  Jennifer S. Gates|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "|02/08/2017|                 1|   AGENDA|      14|Councilmember| Philip T. Kingston|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "|02/08/2017|                 1|   AGENDA|      15|        Mayor|Michael S. Rawlings|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "+----------+------------------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "|      DATE|ITEM_TYPE|DISTRICT|        TITLE|         VOTER NAME|VOTE CAST|FINAL ACTION TAKEN|AGENDA ITEM DESCRIPTION|         AGENDA_ID|             VOTE_ID|ITEM+100|\n",
            "+----------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "|02/08/2017|   AGENDA|      13|Councilmember|  Jennifer S. Gates|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "|02/08/2017|   AGENDA|      14|Councilmember| Philip T. Kingston|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "|02/08/2017|   AGENDA|      15|        Mayor|Michael S. Rawlings|      N/A|  NO ACTION NEEDED|          Call to Order|020817__Special__1|020817__Special__...|     101|\n",
            "+----------+---------+--------+-------------+-------------------+---------+------------------+-----------------------+------------------+--------------------+--------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "7924"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "oxiYLxv2ETMe",
        "outputId": "c8437acd-66db-447e-c953-b732b481ac9e"
      },
      "source": [
        "# Load csv file from .gz (Winrar) file\r\n",
        "aa_dfw_df = spark.read.format('csv').options(Header=True).load('AA_DFW_2018_Departures_Short.csv.gz')\r\n",
        "display(aa_dfw_df.show(4))\r\n",
        "\r\n",
        "# ไม่เห็นจำเป็นต้องเขียนยาวๆ โง่ๆ\r\n",
        "display(spark.read.csv(\"AA_DFW_2018_Departures_Short.csv.gz\", header=True).show(4))\r\n",
        "sdf = spark.read.csv(\"AA_DFW_2018_Departures_Short.csv.gz\", inferSchema=True, header=True)\r\n",
        "\r\n",
        "\r\n",
        "# import string function\r\n",
        "import pyspark.sql.functions as F\r\n",
        "aa_dfw_df = aa_dfw_df.withColumn('airport', F.lower(aa_dfw_df['Destination Airport']))\r\n",
        "\r\n",
        "# Drop the Destination Airport column\r\n",
        "aa_dfw_df = aa_dfw_df.drop(aa_dfw_df['Destination Airport'])\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "display(aa_dfw_df.show(5))\r\n",
        "\r\n",
        "# Add tables to catalog\r\n",
        "aa_dfw_df.createOrReplaceTempView(\"flights\")\r\n",
        "sdf.createOrReplaceTempView(\"voters\")\r\n",
        "display(spark.catalog.listTables())\r\n",
        "\r\n",
        "# Can be used with sql query\r\n",
        "tested_df = spark.sql(\"SELECT * FROM flights WHERE airport = 'hnl'\")\r\n",
        "tested_df.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed time (Minutes)|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|       01/01/2017|         0005|                HNL|                          537|\n",
            "|       01/01/2017|         0007|                OGG|                          498|\n",
            "|       01/01/2017|         0037|                SFO|                          241|\n",
            "|       01/01/2017|         0043|                DTW|                          134|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed time (Minutes)|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "|       01/01/2017|         0005|                HNL|                          537|\n",
            "|       01/01/2017|         0007|                OGG|                          498|\n",
            "|       01/01/2017|         0037|                SFO|                          241|\n",
            "|       01/01/2017|         0043|                DTW|                          134|\n",
            "+-----------------+-------------+-------------------+-----------------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Actual elapsed time (Minutes)|airport|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|       01/01/2017|         0005|                          537|    hnl|\n",
            "|       01/01/2017|         0007|                          498|    ogg|\n",
            "|       01/01/2017|         0037|                          241|    sfo|\n",
            "|       01/01/2017|         0043|                          134|    dtw|\n",
            "|       01/01/2017|         0051|                           88|    stl|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[Table(name='flights', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
              " Table(name='voters', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Actual elapsed time (Minutes)|airport|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "|       01/01/2017|         0005|                          537|    hnl|\n",
            "|       01/01/2017|         0123|                          529|    hnl|\n",
            "|       01/02/2017|         0005|                          537|    hnl|\n",
            "|       01/02/2017|         0123|                          532|    hnl|\n",
            "+-----------------+-------------+-----------------------------+-------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eceSMYDVJxN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3fb4ef-ca05-4941-d7ec-e91e27aba0b4"
      },
      "source": [
        "# Read the Parquet file into flights_df\r\n",
        "flights_df = spark.read.parquet(\"AA_DFW_ALL.parquet\", header=True)\r\n",
        "flights_df = flights_df.withColumnRenamed(\"_c3\", \"flight_duration\")\r\n",
        "\r\n",
        "# Register the temp table\r\n",
        "flights_df.createOrReplaceTempView('flights')\r\n",
        "\r\n",
        "# Run a SQL query of the average flight duration\r\n",
        "avg_duration = spark.sql('SELECT avg(flight_duration) from flights').collect()[0]\r\n",
        "print('The average flight time is: %d' % avg_duration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average flight time is: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6g-NOdsNvGe"
      },
      "source": [
        "### Working with Parquet (No data provided.  These are just instructions.)\r\n",
        "\r\n",
        "# Read Parquet \r\n",
        "df = spark.read.format(\"parquet\").load(\"filename.parquet\")\r\n",
        "df = spark.read.parquet(\"filename.parquet\")\r\n",
        "\r\n",
        "# Write Parquet\r\n",
        "df.write.format(\"parquet\").save(\"filename.parquet\")\r\n",
        "df.write.parquet(\"filename.parquet\")\r\n",
        "\r\n",
        "# Add tables to catalog to be used for sql query\r\n",
        "df.createOrReplaceTempView(\"Table_name\")\r\n",
        "filtered_df = spark.sql(\"SELECT * FROM Table_name WHERE col_1 < 100\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "kJJ457BDmzHc",
        "outputId": "241c7b02-7260-44e7-88d8-c16ac99825d8"
      },
      "source": [
        "### Examples with Parquet ###\r\n",
        "df1 = spark.read.csv(\"AA_DFW_2017_Departures_Short.csv.gz\")\r\n",
        "df2 = spark.read.csv(\"AA_DFW_2018_Departures_Short.csv.gz\")\r\n",
        "\r\n",
        "print(\"df1 and df2 are Spark DataFrame and look like below:\")\r\n",
        "display(df1.show(3))\r\n",
        "display(df2.show(3)); print(\"\\n\")\r\n",
        "\r\n",
        "# View the row count of df1 and df2\r\n",
        "print(\"df1 Count: %d\" % df1.count())\r\n",
        "print(\"df2 Count: %d\" % df2.count()); print(\"\\n\")\r\n",
        "\r\n",
        "# Combine the DataFrames into one\r\n",
        "df3 = df1.union(df2)\r\n",
        "\r\n",
        "# Save the df3 DataFrame in Parquet format\r\n",
        "df3.write.parquet('AA_DFW_ALL.parquet', mode='overwrite')\r\n",
        "\r\n",
        "# Read the Parquet file into a new DataFrame and run a count\r\n",
        "print(spark.read.parquet('AA_DFW_ALL.parquet').count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df1 and df2 are Spark DataFrame and look like below:\n",
            "+-----------------+-------------+-------------------+--------------------+\n",
            "|              _c0|          _c1|                _c2|                 _c3|\n",
            "+-----------------+-------------+-------------------+--------------------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed ti...|\n",
            "|       01/01/2017|         0005|                HNL|                 537|\n",
            "|       01/01/2017|         0007|                OGG|                 498|\n",
            "+-----------------+-------------+-------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-------------+-------------------+--------------------+\n",
            "|              _c0|          _c1|                _c2|                 _c3|\n",
            "+-----------------+-------------+-------------------+--------------------+\n",
            "|Date (MM/DD/YYYY)|Flight Number|Destination Airport|Actual elapsed ti...|\n",
            "|       01/01/2018|         0005|                HNL|                 498|\n",
            "|       01/01/2018|         0007|                OGG|                 501|\n",
            "+-----------------+-------------+-------------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "df1 Count: 139359\n",
            "df2 Count: 119911\n",
            "\n",
            "\n",
            "259270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6VeGcmXov7p",
        "outputId": "deb8137e-0b3c-41b4-a72b-957d966a4436"
      },
      "source": [
        "### Read Parquet File ### (ต้องรัน Cell บนก่อน)\r\n",
        "\r\n",
        "# Read the Parquet file into flights_df\r\n",
        "flights_df = spark.read.parquet(\"AA_DFW_ALL.parquet\", header=True)\r\n",
        "\r\n",
        "# Add this line to be consistent with the question\r\n",
        "flights_df = flights_df.withColumnRenamed(\"_c3\", \"flight_duration\")\r\n",
        "\r\n",
        "# Register the temp table\r\n",
        "flights_df.createOrReplaceTempView('flights')\r\n",
        "\r\n",
        "# Run a SQL query of the average flight duration\r\n",
        "avg_duration = spark.sql('SELECT avg(flight_duration) from flights').collect()[0]\r\n",
        "print('The average flight time is: %d' % avg_duration)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average flight time is: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysK9YFtPlvy2",
        "outputId": "e98dccd3-3654-4dd4-daf5-a51712de7ab9"
      },
      "source": [
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER_NAME\", \"name\")\r\n",
        "voter_df.show(); print(\"\\n\")\r\n",
        "\r\n",
        "# เลือกเฉพาะแถวที่ชื่อขึ้นต้นด้วย m\r\n",
        "print(\"Showing the table with name begining with M.\")\r\n",
        "voter_df.filter(voter_df[\"name\"].like(\"M%\")).show(5); print(\"\\n\")\r\n",
        "\r\n",
        "print(\"Select specific columns: TITLE and name\")\r\n",
        "voter_df.select(\"TITLE\", \"name\").show(5)\r\n",
        "\r\n",
        "# ใช้ .filter หรือ .where ก็ได้\r\n",
        "voter_df.filter(voter_df[\"TITLE\"] == \"Mayor\").show(5)\r\n",
        "voter_df.filter(\"TITLE = 'Deputy Mayor Pro Tem'\").show(5)\r\n",
        "voter_df.filter(\"DATE = '04/25/2018'\").show(5)\r\n",
        "voter_df.filter(~voter_df[\"name\"].isNotNull()).show(5)\r\n",
        "voter_df.filter(voter_df[\"name\"].isNull()).show(5)\r\n",
        "voter_df.filter(voter_df[\"TITLE\"].contains('Vacant')).show(5)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+\n",
            "|      DATE|        TITLE|               name|\n",
            "+----------+-------------+-------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|\n",
            "|02/08/2017|Councilmember|       Scott Griggs|\n",
            "|02/08/2017|Councilmember|   B. Adam  McGough|\n",
            "|02/08/2017|Councilmember|       Lee Kleinman|\n",
            "|02/08/2017|Councilmember|      Sandy Greyson|\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|\n",
            "|02/08/2017|Councilmember| Rickey D. Callahan|\n",
            "|01/11/2017|Councilmember|  Jennifer S. Gates|\n",
            "|04/25/2018|Councilmember|     Sandy  Greyson|\n",
            "|04/25/2018|Councilmember| Jennifer S.  Gates|\n",
            "+----------+-------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "\n",
            "Showing the table with name begining with M.\n",
            "+----------+-------------+-------------------+\n",
            "|      DATE|        TITLE|               name|\n",
            "+----------+-------------+-------------------+\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|\n",
            "|04/25/2018|        Mayor|Michael S. Rawlings|\n",
            "|04/25/2018|Councilmember|      Mark  Clayton|\n",
            "|06/20/2018|        Mayor|Michael S. Rawlings|\n",
            "+----------+-------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "\n",
            "Select specific columns: TITLE and name\n",
            "+-------------+-------------------+\n",
            "|        TITLE|               name|\n",
            "+-------------+-------------------+\n",
            "|Councilmember|  Jennifer S. Gates|\n",
            "|Councilmember| Philip T. Kingston|\n",
            "|        Mayor|Michael S. Rawlings|\n",
            "|Councilmember|       Adam Medrano|\n",
            "|Councilmember|       Casey Thomas|\n",
            "+-------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-----+-------------------+\n",
            "|      DATE|TITLE|               name|\n",
            "+----------+-----+-------------------+\n",
            "|02/08/2017|Mayor|Michael S. Rawlings|\n",
            "|02/08/2017|Mayor|Michael S. Rawlings|\n",
            "|04/25/2018|Mayor|Michael S. Rawlings|\n",
            "|06/20/2018|Mayor|Michael S. Rawlings|\n",
            "|06/20/2018|Mayor|Michael S. Rawlings|\n",
            "+----------+-----+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------------------+------------+\n",
            "|      DATE|               TITLE|        name|\n",
            "+----------+--------------------+------------+\n",
            "|04/25/2018|Deputy Mayor Pro Tem|Adam Medrano|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|Adam Medrano|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|Adam Medrano|\n",
            "|08/15/2018|Deputy Mayor Pro Tem|Adam Medrano|\n",
            "|08/15/2018|Deputy Mayor Pro Tem|Adam Medrano|\n",
            "+----------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------------------+-------------------+\n",
            "|      DATE|               TITLE|               name|\n",
            "+----------+--------------------+-------------------+\n",
            "|04/25/2018|       Councilmember|     Sandy  Greyson|\n",
            "|04/25/2018|       Councilmember| Jennifer S.  Gates|\n",
            "|04/25/2018|       Councilmember|Philip T.  Kingston|\n",
            "|04/25/2018|               Mayor|Michael S. Rawlings|\n",
            "|04/25/2018|Deputy Mayor Pro Tem|       Adam Medrano|\n",
            "+----------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------+----+\n",
            "|                DATE| TITLE|name|\n",
            "+--------------------+------+----+\n",
            "|          08/15/2018|Vacant|null|\n",
            "|          08/15/2018|Vacant|null|\n",
            "|          09/18/2018|Vacant|null|\n",
            "|          09/12/2018|Vacant|null|\n",
            "|[APPOINTMENT OF J...|  null|null|\n",
            "+--------------------+------+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+--------------------+------+----+\n",
            "|                DATE| TITLE|name|\n",
            "+--------------------+------+----+\n",
            "|          08/15/2018|Vacant|null|\n",
            "|          08/15/2018|Vacant|null|\n",
            "|          09/18/2018|Vacant|null|\n",
            "|          09/12/2018|Vacant|null|\n",
            "|[APPOINTMENT OF J...|  null|null|\n",
            "+--------------------+------+----+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+------+----+\n",
            "|      DATE| TITLE|name|\n",
            "+----------+------+----+\n",
            "|08/15/2018|Vacant|null|\n",
            "|08/15/2018|Vacant|null|\n",
            "|09/18/2018|Vacant|null|\n",
            "|09/12/2018|Vacant|null|\n",
            "|10/03/2018|Vacant|null|\n",
            "+----------+------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "00Ih3DZR4GUX",
        "outputId": "5fd922ac-0053-49b2-9edc-1f5162f90555"
      },
      "source": [
        "### Change the datetime format\r\n",
        "from pyspark.sql.functions import year, to_date\r\n",
        "\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "display(voter_df.printSchema())\r\n",
        "\r\n",
        "# The code on Datacamp as of 11 Jan 2021 is incorrect on how to extract year.\r\n",
        "# The following is how to do it properly.\r\n",
        "\r\n",
        "voter_df = voter_df.withColumn('NewDate', to_date(voter_df['Date'], 'MM/dd/yyyy'))\r\n",
        "display(voter_df.printSchema())\r\n",
        "voter_df = voter_df.withColumn('Year', year(voter_df['NewDate']))\r\n",
        "display(voter_df.printSchema())\r\n",
        "voter_df.show(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DATE: string (nullable = true)\n",
            " |-- TITLE: string (nullable = true)\n",
            " |-- VOTER_NAME: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DATE: string (nullable = true)\n",
            " |-- TITLE: string (nullable = true)\n",
            " |-- VOTER_NAME: string (nullable = true)\n",
            " |-- NewDate: date (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- DATE: string (nullable = true)\n",
            " |-- TITLE: string (nullable = true)\n",
            " |-- VOTER_NAME: string (nullable = true)\n",
            " |-- NewDate: date (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+----------+----+\n",
            "|      DATE|        TITLE|         VOTER_NAME|   NewDate|Year|\n",
            "+----------+-------------+-------------------+----------+----+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|2017-02-08|2017|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|2017-02-08|2017|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|2017-02-08|2017|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|2017-02-08|2017|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|2017-02-08|2017|\n",
            "+----------+-------------+-------------------+----------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f2vY8t-l8ow",
        "outputId": "e010469f-6a8e-4a4c-ec74-1b93ef38f74d"
      },
      "source": [
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER_NAME\", \"name\")\r\n",
        "voter_df.withColumn('upper', F.upper(\"name\")).show(5);print(\"\\n\")\r\n",
        "voter_df.withColumn(\"splits\", F.split(\"name\", \" \")).show(5); print(\"\\n\")\r\n",
        "\r\n",
        "# Show the distinct name entries\r\n",
        "print(\"The below table display the distinct voter's names.  Some are too long.\")\r\n",
        "voter_df.select(\"name\").distinct().show(5, truncate=False)\r\n",
        "\r\n",
        "# Filter voter_df where the VOTER_NAME is 1-20 characters in length\r\n",
        "voter_df = voter_df.filter('length(name) > 0 and length(name) < 20')\r\n",
        "print(\"The below table removes the names that are too long.\")\r\n",
        "voter_df.select(\"name\").distinct().show(5, truncate=False)\r\n",
        "\r\n",
        "# Filter out voter_df where the VOTER_NAME contains an underscore\r\n",
        "voter_df = voter_df.filter(~ F.col('name').contains('_'))\r\n",
        "\r\n",
        "# Show the distinct VOTER_NAME entries again\r\n",
        "print(\"The below table removes the underscore from names.\")\r\n",
        "voter_df.select(\"name\").distinct().show(5, truncate=False)\r\n",
        "\r\n",
        "# Add a new column called splits separated on whitespace\r\n",
        "voter_df = voter_df.withColumn(\"splits\", F.split(voter_df[\"name\"], '\\s+'))\r\n",
        "\r\n",
        "# Create a new column called first_name based on the first item in splits\r\n",
        "voter_df = voter_df.withColumn(\"first_name\", voter_df[\"splits\"].getItem(0))\r\n",
        "\r\n",
        "# Get the last entry of the splits list and create a column called last_name\r\n",
        "voter_df = voter_df.withColumn(\"last_name\", voter_df[\"splits\"].getItem(F.size('splits') - 1)) #อย่าลืม มันเริ่มที่ 0 ถ้าขนาด array=3 ตัวสุดท้าย index=2\r\n",
        "\r\n",
        "# Drop the splits column\r\n",
        "voter_df = voter_df.drop('splits')\r\n",
        "\r\n",
        "# Show the voter_df DataFrame\r\n",
        "voter_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+-------------------+\n",
            "|      DATE|        TITLE|               name|              upper|\n",
            "+----------+-------------+-------------------+-------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  JENNIFER S. GATES|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston| PHILIP T. KINGSTON|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|MICHAEL S. RAWLINGS|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|       ADAM MEDRANO|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|       CASEY THOMAS|\n",
            "+----------+-------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "\n",
            "+----------+-------------+-------------------+--------------------+\n",
            "|      DATE|        TITLE|               name|              splits|\n",
            "+----------+-------------+-------------------+--------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|[Jennifer, S., Ga...|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|[Philip, T., King...|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|[Michael, S., Raw...|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|     [Adam, Medrano]|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     [Casey, Thomas]|\n",
            "+----------+-------------+-------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "\n",
            "The below table display the distinct voter's names.  Some are too long.\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|name                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Tennell Atkins                                                                                                                                                                                                                                                                                                                                                                                               |\n",
            "|  the  final   2018 Assessment Plan and the 2018 Assessment  Roll  (to  be  kept  on  file  with  the  City  Secretary);  establishing  classifications  for   the   apportionment   of   costs and the methods of assessing special assessments for the services and improvements to property in the District;  closing  the  hearing  and  levying  a  special  assessment  on  property  in  the  District|\n",
            "|Scott Griggs                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
            "|Scott  Griggs                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "|Sandy Greyson                                                                                                                                                                                                                                                                                                                                                                                                |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The below table removes the names that are too long.\n",
            "+-------------------+\n",
            "|name               |\n",
            "+-------------------+\n",
            "|Tennell Atkins     |\n",
            "|Scott Griggs       |\n",
            "|Scott  Griggs      |\n",
            "|Sandy Greyson      |\n",
            "|Michael S. Rawlings|\n",
            "+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The below table removes the underscore from names.\n",
            "+-------------------+\n",
            "|name               |\n",
            "+-------------------+\n",
            "|Tennell Atkins     |\n",
            "|Scott Griggs       |\n",
            "|Scott  Griggs      |\n",
            "|Sandy Greyson      |\n",
            "|Michael S. Rawlings|\n",
            "+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-------------+-------------------+----------+---------+\n",
            "|      DATE|        TITLE|               name|first_name|last_name|\n",
            "+----------+-------------+-------------------+----------+---------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold|\n",
            "|02/08/2017|Councilmember|       Scott Griggs|     Scott|   Griggs|\n",
            "|02/08/2017|Councilmember|   B. Adam  McGough|        B.|  McGough|\n",
            "|02/08/2017|Councilmember|       Lee Kleinman|       Lee| Kleinman|\n",
            "|02/08/2017|Councilmember|      Sandy Greyson|     Sandy|  Greyson|\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael| Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|  Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|   Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|   Carolyn|   Arnold|\n",
            "|02/08/2017|Councilmember| Rickey D. Callahan|    Rickey| Callahan|\n",
            "|01/11/2017|Councilmember|  Jennifer S. Gates|  Jennifer|    Gates|\n",
            "|04/25/2018|Councilmember|     Sandy  Greyson|     Sandy|  Greyson|\n",
            "|04/25/2018|Councilmember| Jennifer S.  Gates|  Jennifer|    Gates|\n",
            "+----------+-------------+-------------------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkVjuFbAvKPW",
        "outputId": "2b653157-5772-4987-9f13-3ba1799836cc"
      },
      "source": [
        "from pyspark.sql.functions import when\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER_NAME\", \"name\")\r\n",
        "voter_df.select(\"name\", \"TITLE\", F.when(voter_df[\"TITLE\"]=='Mayor', 999)).show(5)\r\n",
        "voter_df.select(\"name\", \"TITLE\", F.when(voter_df[\"TITLE\"]=='Mayor', 999).otherwise(-1)).show(5)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------+--------------------------------------+\n",
            "|               name|        TITLE|CASE WHEN (TITLE = Mayor) THEN 999 END|\n",
            "+-------------------+-------------+--------------------------------------+\n",
            "|  Jennifer S. Gates|Councilmember|                                  null|\n",
            "| Philip T. Kingston|Councilmember|                                  null|\n",
            "|Michael S. Rawlings|        Mayor|                                   999|\n",
            "|       Adam Medrano|Councilmember|                                  null|\n",
            "|       Casey Thomas|Councilmember|                                  null|\n",
            "+-------------------+-------------+--------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-------------------+-------------+----------------------------------------------+\n",
            "|               name|        TITLE|CASE WHEN (TITLE = Mayor) THEN 999 ELSE -1 END|\n",
            "+-------------------+-------------+----------------------------------------------+\n",
            "|  Jennifer S. Gates|Councilmember|                                            -1|\n",
            "| Philip T. Kingston|Councilmember|                                            -1|\n",
            "|Michael S. Rawlings|        Mayor|                                           999|\n",
            "|       Adam Medrano|Councilmember|                                            -1|\n",
            "|       Casey Thomas|Councilmember|                                            -1|\n",
            "+-------------------+-------------+----------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WQRH04_p9g_",
        "outputId": "9e956af2-624d-4a35-a8a5-6a077137702b"
      },
      "source": [
        "# pyspark.sql.functions.when example\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.functions import when\r\n",
        "\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER NAME\", \"name\")\r\n",
        "\r\n",
        "# F.when เป็นการเพิ่มคอลัมน์ ภายใต้เงื่อนไขที่กำหนด\r\n",
        "voter_df = voter_df.withColumn('random_val', when(voter_df[\"TITLE\"]==\"Councilmember\", F.rand()))\r\n",
        "voter_df.show(5)\r\n",
        "\r\n",
        "# Add a column to voter_df for a voter based on their position (when สามารถ chain ต่อเนื่องได้)\r\n",
        "voter_df = voter_df.withColumn('random_val', when(voter_df[\"TITLE\"] == 'Councilmember', F.rand()).when(voter_df[\"TITLE\"] == 'Mayor', 2).otherwise(0))\r\n",
        "\r\n",
        "# Show some of the DataFrame rows\r\n",
        "voter_df.show(5)\r\n",
        "\r\n",
        "# Use the .filter() clause with random_val\r\n",
        "voter_df.filter(\"random_val=0\").show(5) # หรือจะใช้ boolean array ก็ได้\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+-------------------+\n",
            "|      DATE|        TITLE|         VOTER_NAME|         random_val|\n",
            "+----------+-------------+-------------------+-------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|0.23697572340019812|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston| 0.7930585192854953|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|               null|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|0.32088013794978154|\n",
            "|02/08/2017|Councilmember|       Casey Thomas| 0.6939513914868843|\n",
            "+----------+-------------+-------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-------------+-------------------+------------------+\n",
            "|      DATE|        TITLE|         VOTER_NAME|        random_val|\n",
            "+----------+-------------+-------------------+------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|0.3469164732572111|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|0.3125977806495175|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|               2.0|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|0.8665905990339372|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|0.3373992978107322|\n",
            "+----------+-------------+-------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+--------------------+-----------------+----------+\n",
            "|      DATE|               TITLE|       VOTER_NAME|random_val|\n",
            "+----------+--------------------+-----------------+----------+\n",
            "|04/25/2018|Deputy Mayor Pro Tem|     Adam Medrano|       0.0|\n",
            "|04/25/2018|       Mayor Pro Tem|Dwaine R. Caraway|       0.0|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|     Adam Medrano|       0.0|\n",
            "|06/20/2018|       Mayor Pro Tem|Dwaine R. Caraway|       0.0|\n",
            "|06/20/2018|Deputy Mayor Pro Tem|     Adam Medrano|       0.0|\n",
            "+----------+--------------------+-----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBX3gxCblb_n",
        "outputId": "a5d55be6-f458-4f1f-be02-66571107a405"
      },
      "source": [
        "# User-defined function\r\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\r\n",
        "from pyspark.sql.functions import udf\r\n",
        "from random import choice\r\n",
        "\r\n",
        "def reverseString(s):\r\n",
        "    return s[::-1]\r\n",
        "\r\n",
        "def sortingCap():\r\n",
        "    return choice([\"A\", \"B\", \"C\", \"D\"])\r\n",
        "\r\n",
        "# เขียนจากตัวอย่างอื่น แค่เอามาให้ดูว่า udf มีตัวอย่างอะไรบ้าง\r\n",
        "def getAvgSale(saleslist):\r\n",
        "    totalsales, count = 0, 0\r\n",
        "    for sale in saleslist:\r\n",
        "        totalsales += sale[2] + sale[3] # สมมติมูลค่า sales ที่ต้องการหาอยู่ใน index ที่ 2, 3\r\n",
        "        count += 2 # บวกทีละสอง ตามจำนวน sale ด้านบน\r\n",
        "    return totalsales/count # เอามาคำนณค่าเฉลี่ยในแต่ละ row \r\n",
        "\r\n",
        "udfGetAvgSale = udf(getAvgSale, DoubleType())\r\n",
        "# df = df.withColumn(\"avg_sale\", udfGetAvgSale(df[\"sales_list\"]))\r\n",
        "\r\n",
        "# เพราะสาเหตุใดไม่ทราบ แต่ reverse ชื่อที่ยังไม่ clean ไม่ได้\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER_NAME\", \"name\")\r\n",
        "voter_df = voter_df.filter('length(name) > 0 and length(name) < 20')\r\n",
        "voter_df = voter_df.filter(~ F.col('name').contains('_'))\r\n",
        "voter_df = voter_df.withColumn(\"splits\", F.split(voter_df[\"name\"], '\\s+'))\r\n",
        "voter_df = voter_df.withColumn(\"first_name\", voter_df[\"splits\"].getItem(0))\r\n",
        "user_df = voter_df.select(\"DATE\", \"TITLE\", \"name\", \"first_name\")\r\n",
        "\r\n",
        "# udf ต้องมี 2 positional arguments: ฟังก์ชัน และชนิดของค่าที่ return\r\n",
        "udfReverseString = udf(reverseString, StringType())\r\n",
        "udfReverseString2 = udf(lambda s: s[::-1], StringType())\r\n",
        "user_df = user_df.withColumn('ReverseName', udfReverseString2(user_df[\"name\"]))\r\n",
        "user_df.show(5)\r\n",
        "\r\n",
        "udfSortingCap = udf(sortingCap, StringType())\r\n",
        "user_df.withColumn(\"Grade\", udfSortingCap()).show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+----------+-------------------+\n",
            "|      DATE|        TITLE|               name|first_name|        ReverseName|\n",
            "+----------+-------------+-------------------+----------+-------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|  setaG .S refinneJ|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| notsgniK .T pilihP|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael|sgnilwaR .S leahciM|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|       onardeM madA|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|       samohT yesaC|\n",
            "+----------+-------------+-------------------+----------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-------------+-------------------+----------+-------------------+-----+\n",
            "|      DATE|        TITLE|               name|first_name|        ReverseName|Grade|\n",
            "+----------+-------------+-------------------+----------+-------------------+-----+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|  Jennifer|  setaG .S refinneJ|    A|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|    Philip| notsgniK .T pilihP|    B|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|   Michael|sgnilwaR .S leahciM|    B|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|      Adam|       onardeM madA|    A|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     Casey|       samohT yesaC|    B|\n",
            "+----------+-------------+-------------------+----------+-------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YTVoYbA5dFY",
        "outputId": "8397a5d7-8e7f-467b-fe3c-6eaa00599872"
      },
      "source": [
        "### udf examples get the middle names\r\n",
        "# These parts of codes come from previous examples.\r\n",
        "from pyspark.sql.functions import udf\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = voter_df.withColumnRenamed(\"VOTER_NAME\", \"name\")\r\n",
        "voter_df = voter_df.filter('length(name) > 0 and length(name) < 20')\r\n",
        "voter_df = voter_df.filter(~ F.col('name').contains('_'))\r\n",
        "voter_df = voter_df.withColumn(\"splits\", F.split(voter_df[\"name\"], '\\s+'))\r\n",
        "voter_df = voter_df.withColumn(\"first_name\", voter_df[\"splits\"].getItem(0)).withColumn(\"last_name\",  voter_df[\"splits\"].getItem(F.size(voter_df[\"splits\"])-1))\r\n",
        "voter_df.show(5)\r\n",
        "udfFirstAndMiddle = udf(lambda s: ' '.join([s[0], s[1]]), StringType())\r\n",
        "\r\n",
        "# Create a new column using your UDF\r\n",
        "voter_df = voter_df.withColumn('first_and_middle_name', udfFirstAndMiddle(voter_df[\"splits\"]))\r\n",
        "\r\n",
        "# Show the DataFrame\r\n",
        "voter_df.show()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-------------------+--------------------+----------+---------+\n",
            "|      DATE|        TITLE|               name|              splits|first_name|last_name|\n",
            "+----------+-------------+-------------------+--------------------+----------+---------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|[Jennifer, S., Ga...|  Jennifer|    Gates|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|[Philip, T., King...|    Philip| Kingston|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|[Michael, S., Raw...|   Michael| Rawlings|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|     [Adam, Medrano]|      Adam|  Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     [Casey, Thomas]|     Casey|   Thomas|\n",
            "+----------+-------------+-------------------+--------------------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------+-------------+-------------------+--------------------+----------+---------+---------------------+\n",
            "|      DATE|        TITLE|               name|              splits|first_name|last_name|first_and_middle_name|\n",
            "+----------+-------------+-------------------+--------------------+----------+---------+---------------------+\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|[Jennifer, S., Ga...|  Jennifer|    Gates|          Jennifer S.|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|[Philip, T., King...|    Philip| Kingston|            Philip T.|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|[Michael, S., Raw...|   Michael| Rawlings|           Michael S.|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|     [Adam, Medrano]|      Adam|  Medrano|         Adam Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     [Casey, Thomas]|     Casey|   Thomas|         Casey Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, A...|   Carolyn|   Arnold|         Carolyn King|\n",
            "|02/08/2017|Councilmember|       Scott Griggs|     [Scott, Griggs]|     Scott|   Griggs|         Scott Griggs|\n",
            "|02/08/2017|Councilmember|   B. Adam  McGough| [B., Adam, McGough]|        B.|  McGough|              B. Adam|\n",
            "|02/08/2017|Councilmember|       Lee Kleinman|     [Lee, Kleinman]|       Lee| Kleinman|         Lee Kleinman|\n",
            "|02/08/2017|Councilmember|      Sandy Greyson|    [Sandy, Greyson]|     Sandy|  Greyson|        Sandy Greyson|\n",
            "|02/08/2017|Councilmember|  Jennifer S. Gates|[Jennifer, S., Ga...|  Jennifer|    Gates|          Jennifer S.|\n",
            "|02/08/2017|Councilmember| Philip T. Kingston|[Philip, T., King...|    Philip| Kingston|            Philip T.|\n",
            "|02/08/2017|        Mayor|Michael S. Rawlings|[Michael, S., Raw...|   Michael| Rawlings|           Michael S.|\n",
            "|02/08/2017|Councilmember|       Adam Medrano|     [Adam, Medrano]|      Adam|  Medrano|         Adam Medrano|\n",
            "|02/08/2017|Councilmember|       Casey Thomas|     [Casey, Thomas]|     Casey|   Thomas|         Casey Thomas|\n",
            "|02/08/2017|Councilmember|Carolyn King Arnold|[Carolyn, King, A...|   Carolyn|   Arnold|         Carolyn King|\n",
            "|02/08/2017|Councilmember| Rickey D. Callahan|[Rickey, D., Call...|    Rickey| Callahan|            Rickey D.|\n",
            "|01/11/2017|Councilmember|  Jennifer S. Gates|[Jennifer, S., Ga...|  Jennifer|    Gates|          Jennifer S.|\n",
            "|04/25/2018|Councilmember|     Sandy  Greyson|    [Sandy, Greyson]|     Sandy|  Greyson|        Sandy Greyson|\n",
            "|04/25/2018|Councilmember| Jennifer S.  Gates|[Jennifer, S., Ga...|  Jennifer|    Gates|          Jennifer S.|\n",
            "+----------+-------------+-------------------+--------------------+----------+---------+---------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tghZsvVnyU5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624cdab1-186c-4353-c9d7-3c61f90fa9c0"
      },
      "source": [
        "### More Examples and notice how number of partitions affect pyspark.sql.functions.monotonically_increasing_id()\r\n",
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "# Select all the unique council voters\r\n",
        "df = spark.read.csv(\"DallasCouncilVotes.csv.gz\", header=True, inferSchema=True)\r\n",
        "voter_df = df.select(\"VOTER NAME\").distinct()\r\n",
        "# voter_df_single = voter_df.repartition(1) # This is costly\r\n",
        "voter_df_single = voter_df.coalesce(1)\r\n",
        "\r\n",
        "# Count the rows in voter_df\r\n",
        "print(\"\\nThere are %d rows in the voter_df DataFrame.\\n\" % voter_df.count())\r\n",
        "\r\n",
        "# Add a ROW_ID ใช้ฟังก์ชัน F.monotonically_increasing_id \r\n",
        "voter_df = voter_df.withColumn('ROW_ID', F.monotonically_increasing_id())\r\n",
        "\r\n",
        "# Show the rows with 10 highest IDs in the set\r\n",
        "voter_df.orderBy(voter_df[\"ROW_ID\"].desc()).show(10)\r\n",
        "\r\n",
        "# Print the number of partitions in each DataFrame\r\n",
        "print(\"\\nThere are %d partitions in the voter_df DataFrame.\\n\" % voter_df.rdd.getNumPartitions())\r\n",
        "print(\"\\nThere are %d partitions in the voter_df_single DataFrame.\\n\" % voter_df_single.rdd.getNumPartitions())\r\n",
        "\r\n",
        "# Add a ROW_ID field to each DataFrame\r\n",
        "voter_df = voter_df.withColumn('ROW_ID', F.monotonically_increasing_id())\r\n",
        "voter_df_single = voter_df_single.withColumn('ROW_ID', F.monotonically_increasing_id())\r\n",
        "\r\n",
        "# Show the top 10 IDs in each DataFrame \r\n",
        "voter_df.orderBy(voter_df[\"ROW_ID\"].desc()).show(10)\r\n",
        "voter_df_single.orderBy(voter_df_single[\"ROW_ID\"].desc()).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "There are 36 rows in the voter_df DataFrame.\n",
            "\n",
            "+--------------------+-------------+\n",
            "|          VOTER NAME|       ROW_ID|\n",
            "+--------------------+-------------+\n",
            "|        Lee Kleinman|4286377361408|\n",
            "| Rickey D.  Callahan|4174708211712|\n",
            "|   the   final  2...|4020089389056|\n",
            "|   the   final  2...|3831110828032|\n",
            "|   Jennifer S. Gates|3770981285888|\n",
            "| Philip T.  Kingston|3762391351296|\n",
            "|  Jennifer S.  Gates|3539053051904|\n",
            "|       Scott  Griggs|3478923509760|\n",
            "|        Scott Griggs|3470333575168|\n",
            "|   Casey  Thomas, II|3384434229248|\n",
            "+--------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "There are 500 partitions in the voter_df DataFrame.\n",
            "\n",
            "\n",
            "There are 1 partitions in the voter_df_single DataFrame.\n",
            "\n",
            "+--------------------+-------------+\n",
            "|          VOTER NAME|       ROW_ID|\n",
            "+--------------------+-------------+\n",
            "|        Lee Kleinman|4286377361408|\n",
            "| Rickey D.  Callahan|4174708211712|\n",
            "|   the   final  2...|4020089389056|\n",
            "|   the   final  2...|3831110828032|\n",
            "|   Jennifer S. Gates|3770981285888|\n",
            "| Philip T.  Kingston|3762391351296|\n",
            "|  Jennifer S.  Gates|3539053051904|\n",
            "|       Scott  Griggs|3478923509760|\n",
            "|        Scott Griggs|3470333575168|\n",
            "|   Casey  Thomas, II|3384434229248|\n",
            "+--------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------------------+------+\n",
            "|          VOTER NAME|ROW_ID|\n",
            "+--------------------+------+\n",
            "|        Lee Kleinman|    35|\n",
            "| Rickey D.  Callahan|    34|\n",
            "|   the   final  2...|    33|\n",
            "|   the   final  2...|    32|\n",
            "|   Jennifer S. Gates|    31|\n",
            "| Philip T.  Kingston|    30|\n",
            "|  Jennifer S.  Gates|    29|\n",
            "|       Scott  Griggs|    28|\n",
            "|        Scott Griggs|    27|\n",
            "|   Casey  Thomas, II|    26|\n",
            "+--------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILtBxq1L3PQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7261c1f1-d301-472e-9748-66c98b3298c0"
      },
      "source": [
        "### Caching\r\n",
        "import pyspark.sql.functions as F\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "\r\n",
        "# Call .cache() on the DataFrame before Action\r\n",
        "voter_df.cache().show(2)\r\n",
        "print(\"Call .cache() on the DataFrame before Action.\")\r\n",
        "print(f'The number of rows in voter_df is {voter_df.cache().count()}.\\n')\r\n",
        "\r\n",
        "# Call cache separately\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True).withColumn(\"ID\", F.monotonically_increasing_id())\r\n",
        "voter_df = voter_df.cache()\r\n",
        "voter_df.show(2)\r\n",
        "\r\n",
        "# Check cache\r\n",
        "print(voter_df.is_cached)\r\n",
        "\r\n",
        "# Remove cache\r\n",
        "voter_df.unpersist()\r\n",
        "print(voter_df.is_cached)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+------------------+\n",
            "|      DATE|        TITLE|        VOTER_NAME|\n",
            "+----------+-------------+------------------+\n",
            "|02/08/2017|Councilmember| Jennifer S. Gates|\n",
            "|02/08/2017|Councilmember|Philip T. Kingston|\n",
            "+----------+-------------+------------------+\n",
            "only showing top 2 rows\n",
            "\n",
            "Call .cache() on the DataFrame before Action.\n",
            "The number of rows in voter_df is 44625.\n",
            "\n",
            "+----------+-------------+------------------+---+\n",
            "|      DATE|        TITLE|        VOTER_NAME| ID|\n",
            "+----------+-------------+------------------+---+\n",
            "|02/08/2017|Councilmember| Jennifer S. Gates|  0|\n",
            "|02/08/2017|Councilmember|Philip T. Kingston|  1|\n",
            "+----------+-------------+------------------+---+\n",
            "only showing top 2 rows\n",
            "\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSaW_9yUVErx",
        "outputId": "06ff8fce-55bd-4d64-cf81-a1e57cdf6847"
      },
      "source": [
        "### More caching\r\n",
        "import time\r\n",
        "departures_df = spark.read.csv(\"AA_DFW_2018_Departures_Short.csv.gz\", header=True, inferSchema=True)\r\n",
        "start_time = time.time()\r\n",
        "\r\n",
        "# Add caching to the unique rows in departures_df\r\n",
        "departures_df = departures_df.distinct().cache()\r\n",
        "\r\n",
        "# Count the unique rows in departures_df, noting how long the operation takes\r\n",
        "print(\"Counting %d rows took %f seconds\" % (departures_df.count(), time.time() - start_time))\r\n",
        "\r\n",
        "# Count the rows again, noting the variance in time of a cached DataFrame\r\n",
        "start_time = time.time()\r\n",
        "print(\"Counting %d rows again took %f seconds\" % (departures_df.count(), time.time() - start_time))\r\n",
        "\r\n",
        "# Determine if departures_df is in the cache\r\n",
        "print(\"Is departures_df cached?: %s\" % departures_df.is_cached)\r\n",
        "print(\"Removing departures_df from cache\")\r\n",
        "\r\n",
        "# Remove departures_df from the cache\r\n",
        "departures_df.unpersist()\r\n",
        "\r\n",
        "# Check the cache status again\r\n",
        "print(\"Is departures_df cached?: %s\" % departures_df.is_cached)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting 119910 rows took 7.821194 seconds\n",
            "Counting 119910 rows again took 1.771794 seconds\n",
            "Is departures_df cached?: True\n",
            "Removing departures_df from cache\n",
            "Is departures_df cached?: False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EbZ4Oqm9c_j",
        "outputId": "fcc47de8-f6ec-48dc-fa8b-79a6a0b14abd"
      },
      "source": [
        "### How to split objects\r\n",
        "\r\n",
        "# Use OS utilities\r\n",
        "#### split -l 10000 -d largefilename chunk- ####\r\n",
        "# -l 10000 คือจำนวนบรรทัด\r\n",
        "# -d ใช้ตัวเลขเป็น suffix\r\n",
        "# largefilename คือชื่อไฟล์\r\n",
        "# chunk- เป็น prefix\r\n",
        "\r\n",
        "# เขียนลง parquet\r\n",
        "df_csv =  spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True)\r\n",
        "\r\n",
        "# สมมติมี voterdata000.csv - voterdata999.csv\r\n",
        "# ใช้ df_csv =  spark.read.csv(\"voterdata*.csv\", header=True, inferSchema=True)\r\n",
        "\r\n",
        "df_csv =  df_csv.withColumnRenamed(\"VOTER_NAME\", \"name\") # ไฟล์ parquet ไม่สามารถใช้ชื่อคอลัมน์มี space ได้ contains invalid character(s) among \" ,;{}()\\n\\t=\r\n",
        "df_csv.show(1)\r\n",
        "df_csv =  df_csv.select(\"DATE\", \"name\")\r\n",
        "df_csv.write.parquet(\"data3.parquet\")\r\n",
        "df_pq = spark.read.parquet(\"data3.parquet\")\r\n",
        "df_pq.show(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------+-----------------+\n",
            "|      DATE|        TITLE|             name|\n",
            "+----------+-------------+-----------------+\n",
            "|02/08/2017|Councilmember|Jennifer S. Gates|\n",
            "+----------+-------------+-----------------+\n",
            "only showing top 1 row\n",
            "\n",
            "+----------+-------------------+\n",
            "|      DATE|               name|\n",
            "+----------+-------------------+\n",
            "|02/08/2017|  Jennifer S. Gates|\n",
            "|02/08/2017| Philip T. Kingston|\n",
            "|02/08/2017|Michael S. Rawlings|\n",
            "|02/08/2017|       Adam Medrano|\n",
            "+----------+-------------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYxjbvaz1C33",
        "outputId": "02767e6e-ac31-445b-e68c-2490f04cac3b"
      },
      "source": [
        "### Reading Spark configurations\r\n",
        "\r\n",
        "# Name of the Spark application instance\r\n",
        "app_name = spark.conf.get(\"spark.app.name\")\r\n",
        "  \r\n",
        "# ถ้าจะเขียน config ให้เขียน app_name = spark.conf.set(\"pyspark-shell\")\r\n",
        "\r\n",
        "# Driver TCP port\r\n",
        "driver_tcp_port = spark.conf.get(\"spark.driver.port\")\r\n",
        "\r\n",
        "# Number of join partitions\r\n",
        "num_partitions = spark.conf.get('spark.sql.shuffle.partitions')\r\n",
        "\r\n",
        "# Show the results\r\n",
        "print(\"Name: %s\" % app_name)\r\n",
        "print(\"Driver TCP port: %s\" % driver_tcp_port)\r\n",
        "print(\"Number of partitions: %s\" % num_partitions, \"\\n\\n\")\r\n",
        "\r\n",
        "# Set Spark config\r\n",
        "\r\n",
        "# Store the number of partitions in variable.  Question asks to set distinct rows\r\n",
        "departures_df = spark.read.csv('AA_DFW_2018_Departures_Short.csv.gz').distinct()\r\n",
        "before = departures_df.rdd.getNumPartitions()\r\n",
        "\r\n",
        "# Configure Spark to use 500 partitions\r\n",
        "spark.conf.set('spark.sql.shuffle.partitions', 500)\r\n",
        "\r\n",
        "# Recreate the DataFrame using the departures data file\r\n",
        "departures_df = spark.read.csv('AA_DFW_2017_Departures_Short.csv.gz').distinct()\r\n",
        "\r\n",
        "# Print the number of partitions for each instance\r\n",
        "print(\"Partition count before change: %d\" % before)\r\n",
        "print(\"Partition count after change: %d\" % departures_df.rdd.getNumPartitions())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: pyspark-shell\n",
            "Driver TCP port: 35617\n",
            "Number of partitions: 200 \n",
            "\n",
            "\n",
            "Partition count before change: 200\n",
            "Partition count after change: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSDjLOgSZoS0",
        "outputId": "700960af-ee6b-4b79-cf98-ce7dbb78a3ed"
      },
      "source": [
        "### Performance Improvements using F.broadcast in join method\r\n",
        "### Tips: use F.broadcast(smaller_df)\r\n",
        "### ถ้า smaller_df เล็กกว่ามากๆ อาจจะไม่ต้องใช้ broadcast\r\n",
        "\r\n",
        "import pyspark.sql.functions as F\r\n",
        "voter_df = spark.read.csv(\"DallasCouncilVoters.csv.gz\", header=True, inferSchema=True).select(\"VOTER_NAME\").distinct()\r\n",
        "\r\n",
        "# To understand performance implications of Spark, use .explain method on a spark dataframe\r\n",
        "voter_df.explain()\r\n",
        "\r\n",
        "# Join the flights_df and aiports_df DataFrames\r\n",
        "flights_df = spark.read.csv(\"AA_DFW_2018_Departures_Short.csv.gz\",  header=True, inferSchema=True)\r\n",
        "airports_df = spark.read.csv(\"airportnames.txt.gz\",  header=True, inferSchema=True)\r\n",
        "normal_df = flights_df.join(airports_df,flights_df[\"Destination Airport\"]==airports_df[\"IATA\"] )\r\n",
        "\r\n",
        "# Show the query plan\r\n",
        "normal_df.explain()\r\n",
        "\r\n",
        "broadcast_df = flights_df.join(F.broadcast(airports_df), flights_df[\"Destination Airport\"] == airports_df[\"IATA\"] )\r\n",
        "\r\n",
        "# Show the query plan and compare against the original\r\n",
        "broadcast_df.explain()\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "# Count the number of rows in the normal DataFrame\r\n",
        "normal_count = normal_df.count()\r\n",
        "normal_duration = time.time() - start_time\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "# Count the number of rows in the broadcast DataFrame\r\n",
        "broadcast_count = broadcast_df.count()\r\n",
        "broadcast_duration = time.time() - start_time\r\n",
        "\r\n",
        "# Print the counts and the duration of the tests\r\n",
        "print(\"Normal count:\\t\\t%d\\tduration: %f\" % (normal_count, normal_duration))\r\n",
        "print(\"Broadcast count:\\t%d\\tduration: %f\" % (broadcast_count, broadcast_duration))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "== Physical Plan ==\n",
            "*(2) HashAggregate(keys=[VOTER_NAME#1032], functions=[])\n",
            "+- Exchange hashpartitioning(VOTER_NAME#1032, 500), true, [id=#1527]\n",
            "   +- *(1) HashAggregate(keys=[VOTER_NAME#1032], functions=[])\n",
            "      +- FileScan csv [VOTER_NAME#1032] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/content/DallasCouncilVoters.csv.gz], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<VOTER_NAME:string>\n",
            "\n",
            "\n",
            "== Physical Plan ==\n",
            "*(2) BroadcastHashJoin [Destination Airport#1055], [IATA#1078], Inner, BuildRight\n",
            ":- *(2) Project [Date (MM/DD/YYYY)#1053, Flight Number#1054, Destination Airport#1055, Actual elapsed time (Minutes)#1056]\n",
            ":  +- *(2) Filter isnotnull(Destination Airport#1055)\n",
            ":     +- FileScan csv [Date (MM/DD/YYYY)#1053,Flight Number#1054,Destination Airport#1055,Actual elapsed time (Minutes)#1056] Batched: false, DataFilters: [isnotnull(Destination Airport#1055)], Format: CSV, Location: InMemoryFileIndex[file:/content/AA_DFW_2018_Departures_Short.csv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(Destination Airport)], ReadSchema: struct<Date (MM/DD/YYYY):string,Flight Number:int,Destination Airport:string,Actual elapsed time ...\n",
            "+- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, true])), [id=#1597]\n",
            "   +- *(1) Project [AIRPORTNAME#1077, IATA#1078]\n",
            "      +- *(1) Filter isnotnull(IATA#1078)\n",
            "         +- FileScan csv [AIRPORTNAME#1077,IATA#1078] Batched: false, DataFilters: [isnotnull(IATA#1078)], Format: CSV, Location: InMemoryFileIndex[file:/content/airportnames.txt.gz], PartitionFilters: [], PushedFilters: [IsNotNull(IATA)], ReadSchema: struct<AIRPORTNAME:string,IATA:string>\n",
            "\n",
            "\n",
            "== Physical Plan ==\n",
            "*(2) BroadcastHashJoin [Destination Airport#1055], [IATA#1078], Inner, BuildRight\n",
            ":- *(2) Project [Date (MM/DD/YYYY)#1053, Flight Number#1054, Destination Airport#1055, Actual elapsed time (Minutes)#1056]\n",
            ":  +- *(2) Filter isnotnull(Destination Airport#1055)\n",
            ":     +- FileScan csv [Date (MM/DD/YYYY)#1053,Flight Number#1054,Destination Airport#1055,Actual elapsed time (Minutes)#1056] Batched: false, DataFilters: [isnotnull(Destination Airport#1055)], Format: CSV, Location: InMemoryFileIndex[file:/content/AA_DFW_2018_Departures_Short.csv.gz], PartitionFilters: [], PushedFilters: [IsNotNull(Destination Airport)], ReadSchema: struct<Date (MM/DD/YYYY):string,Flight Number:int,Destination Airport:string,Actual elapsed time ...\n",
            "+- BroadcastExchange HashedRelationBroadcastMode(List(input[1, string, true])), [id=#1629]\n",
            "   +- *(1) Project [AIRPORTNAME#1077, IATA#1078]\n",
            "      +- *(1) Filter isnotnull(IATA#1078)\n",
            "         +- FileScan csv [AIRPORTNAME#1077,IATA#1078] Batched: false, DataFilters: [isnotnull(IATA#1078)], Format: CSV, Location: InMemoryFileIndex[file:/content/airportnames.txt.gz], PartitionFilters: [], PushedFilters: [IsNotNull(IATA)], ReadSchema: struct<AIRPORTNAME:string,IATA:string>\n",
            "\n",
            "\n",
            "Normal count:\t\t119910\tduration: 0.461668\n",
            "Broadcast count:\t119910\tduration: 0.573637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a736GuQl8Uqd"
      },
      "source": [
        "### Data Pipelines\r\n",
        "\r\n",
        "# Import the data to a DataFrame\r\n",
        "departures_df = spark.read.csv(\"AA_DFW_2015_Departures_Short.csv.gz\", header=True)\r\n",
        "\r\n",
        "# Remove any duration of 0\r\n",
        "departures_df = departures_df.filter(departures_df[\"Actual elapsed time (Minutes)\"] > 0)\r\n",
        "# departures_df = departures_df.filter(departures_df[3] > 0) ก็ได้เหมือนกัน\r\n",
        "\r\n",
        "# Add an ID column\r\n",
        "departures_df = departures_df.withColumn('id', F.monotonically_increasing_id())\r\n",
        "\r\n",
        "# Write the file out to JSON format\r\n",
        "departures_df.write.json(\"output.json\", mode='overwrite')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gZhuVS_Qhku",
        "outputId": "c7fa6e76-8eba-4aa1-9095-6269da7ee072"
      },
      "source": [
        "### Removng commented lines\r\n",
        "\r\n",
        "# df = spark.read.csv(\"datafile.csv\", comment=\"#\") เอาแถวที่มีเครื่องหมาย # ออกไป\r\n",
        "\r\n",
        "import pyspark.sql.functions as F\r\n",
        "from pyspark.sql.functions import col\r\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, DoubleType\r\n",
        "\r\n",
        "\r\n",
        "# Import the file to a DataFrame and perform a row count\r\n",
        "annotations_df = spark.read.csv('annotations.csv.gz', sep=\"|\")\r\n",
        "full_count = annotations_df.count()\r\n",
        "\r\n",
        "print(\"The initial data looks as below:\")\r\n",
        "annotations_df.show(5)\r\n",
        "\r\n",
        "# Count the number of rows beginning with '#'\r\n",
        "comment_count = annotations_df.where(col('_c0').startswith('#')).count()\r\n",
        "print(\"The commented lines looks like below:\")\r\n",
        "annotations_df.filter(col('_c0').startswith('#')).show(5)\r\n",
        "\r\n",
        "# Import the file to a new DataFrame, without commented rows\r\n",
        "no_comments_df = spark.read.csv('annotations.csv.gz', sep=\"|\", comment='#')\r\n",
        "\r\n",
        "# Count the new DataFrame and verify the difference is as expected\r\n",
        "no_comments_count = no_comments_df.count()\r\n",
        "print(\"Full count: %d\\nComment count: %d\\nRemaining count: %d\" % (full_count, comment_count, no_comments_count), \"\\n\")\r\n",
        "\r\n",
        "### Removing invalid rows ###\r\n",
        "\r\n",
        "# Split _c0 on the tab character and store the list in a variable\r\n",
        "tmp_fields = F.split(annotations_df['_c0'], \"\\t\")\r\n",
        "print(\"F.split(annotations_df['_c0'],'\\\\t') is of type\", type(F.split(annotations_df['_c0'], '\\t')), \"\\n\")\r\n",
        "\r\n",
        "# Create the colcount column on the DataFrame\r\n",
        "annotations_df = annotations_df.withColumn('colcount', F.size(tmp_fields))\r\n",
        "\r\n",
        "# Remove any rows containing fewer than 5 fields\r\n",
        "annotations_df_filtered = annotations_df.filter(\"colcount < 5\")\r\n",
        "\r\n",
        "# Count the number of rows\r\n",
        "final_count = annotations_df_filtered.count()\r\n",
        "print(\"Initial count: %d\\nFinal count: %d\" % (no_comments_count, final_count))\r\n",
        "print(\"The current data looks like this:\")\r\n",
        "annotations_df_filtered.show(5)\r\n",
        "\r\n",
        "### Splitting into columns ###\r\n",
        "\r\n",
        "# The question use this DataFrame.  It didn't use the filtered one.\r\n",
        "annotations_df = annotations_df.filter(\"colcount >= 5\")\r\n",
        "\r\n",
        "# Split the content of _c0 on the tab character (aka, '\\t')\r\n",
        "split_cols = F.split(annotations_df['_c0'], '\\t')\r\n",
        "\r\n",
        "# Add the columns folder, filename, width, and height\r\n",
        "split_df = annotations_df.withColumn('folder', split_cols.getItem(0))\r\n",
        "split_df = split_df.withColumn('filename', split_cols.getItem(1))\r\n",
        "split_df = split_df.withColumn('width', split_cols.getItem(2))\r\n",
        "split_df = split_df.withColumn('height', split_cols.getItem(3))\r\n",
        "\r\n",
        "# Add split_cols as a column\r\n",
        "split_df = split_df.withColumn('split_cols', split_cols)\r\n",
        "print(\"Now the dataframe looks like this\")\r\n",
        "split_df.show(5)\r\n",
        "\r\n",
        "\r\n",
        "### Using F.udf\r\n",
        "\r\n",
        "# First we need to know where the numeber 4 comes from\r\n",
        "print(\"First we need to know where the numeber 4 comes from.\")\r\n",
        "print(\"Using the keyword argument 'truncate=False' in .show() method reveals the details.\")\r\n",
        "split_df.select(\"split_cols\").show(15, truncate=False)\r\n",
        "print(\"Notice that the breed names start at index 4 onward.\")\r\n",
        "print(\"Some rows have more than one dog information. \\n\")\r\n",
        "\r\n",
        "def retriever(cols, colcount):\r\n",
        "  # Return a list of dog data\r\n",
        "  return cols[4:colcount]\r\n",
        "\r\n",
        "# Define the method as a UDF\r\n",
        "udfRetriever = F.udf(retriever, ArrayType(StringType()))\r\n",
        "udfRetriever_lambda = F.udf(lambda x: x[4:], ArrayType(StringType()))\r\n",
        "\r\n",
        "# Create a new column using your UDF\r\n",
        "split_df = split_df.withColumn('dog_list', udfRetriever(split_df[\"split_cols\"], split_df[\"colcount\"]))\r\n",
        "split_df_lambda = split_df.withColumn('dog_list', udfRetriever_lambda(split_df[\"split_cols\"]))\r\n",
        "\r\n",
        "# Remove the original column, split_cols, and the colcount\r\n",
        "split_df = split_df.drop('_c0').drop('colcount').drop('split_cols')\r\n",
        "split_df_lambda = split_df.drop('_c0').drop('colcount').drop('split_cols')\r\n",
        "print(\"The final data look like this\")\r\n",
        "split_df.show(5)\r\n",
        "\r\n",
        "# Check if the lambda version of udf returns to same dataframe\r\n",
        "print(f\"Does the lambda version of udf return to same dataframe?: {(split_df.toPandas()).equals(split_df_lambda.toPandas())} \")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The initial data looks as below:\n",
            "+--------------------+\n",
            "|                 _c0|\n",
            "+--------------------+\n",
            "|025865917\tn023521...|\n",
            "|022684404\tn029380...|\n",
            "|021267273\tn022910...|\n",
            "|02110627\tn0211062...|\n",
            "|02093754\tn0209375...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "The commented lines looks like below:\n",
            "+------+\n",
            "|   _c0|\n",
            "+------+\n",
            "| # 339|\n",
            "| # 968|\n",
            "|# 1321|\n",
            "|# 1251|\n",
            "|# 1402|\n",
            "+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Full count: 32794\n",
            "Comment count: 1416\n",
            "Remaining count: 31378 \n",
            "\n",
            "F.split(annotations_df['_c0'],'\\t') is of type <class 'pyspark.sql.column.Column'> \n",
            "\n",
            "Initial count: 31378\n",
            "Final count: 12214\n",
            "The current data looks like this:\n",
            "+--------------------+--------+\n",
            "|                 _c0|colcount|\n",
            "+--------------------+--------+\n",
            "|025865917\tn023521...|       2|\n",
            "|022684404\tn029380...|       2|\n",
            "|021267273\tn022910...|       2|\n",
            "|023200662\tn023050...|       2|\n",
            "|028666219\tn025734...|       2|\n",
            "+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Now the dataframe looks like this\n",
            "+--------------------+--------+--------+---------------+-----+------+--------------------+\n",
            "|                 _c0|colcount|  folder|       filename|width|height|          split_cols|\n",
            "+--------------------+--------+--------+---------------+-----+------+--------------------+\n",
            "|02110627\tn0211062...|       5|02110627|n02110627_12938|  200|   300|[02110627, n02110...|\n",
            "|02093754\tn0209375...|       5|02093754| n02093754_1148|  500|   378|[02093754, n02093...|\n",
            "|%s\t%s\t800\t600\tShe...|       5|      %s|             %s|  800|   600|[%s, %s, 800, 600...|\n",
            "|02104029\tn0210402...|       5|02104029|   n02104029_63|  500|   375|[02104029, n02104...|\n",
            "|02111500\tn0211150...|       5|02111500| n02111500_5137|  500|   375|[02111500, n02111...|\n",
            "+--------------------+--------+--------+---------------+-----+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "First we need to know where the numeber 4 comes from.\n",
            "Using the keyword argument 'truncate=False' in .show() method reveals the details.\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "|split_cols                                                                                  |\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "|[02110627, n02110627_12938, 200, 300, affenpinscher,0,9,173,298]                            |\n",
            "|[02093754, n02093754_1148, 500, 378, Border_terrier,73,127,341,335]                         |\n",
            "|[%s, %s, 800, 600, Shetland_sheepdog,124,87,576,514]                                        |\n",
            "|[02104029, n02104029_63, 500, 375, kuvasz,0,0,499,327]                                      |\n",
            "|[02111500, n02111500_5137, 500, 375, Great_Pyrenees,124,225,403,374]                        |\n",
            "|[02104365, n02104365_7518, 500, 333, schipperke,146,29,416,309]                             |\n",
            "|[02105056, n02105056_2834, 500, 375, groenendael,168,0,469,374]                             |\n",
            "|[02093647, n02093647_541, 500, 333, Bedlington_terrier,10,12,462,332]                       |\n",
            "|[02098413, n02098413_1355, 500, 375, Lhasa,39,1,499,373]                                    |\n",
            "|[02093859, n02093859_2309, 330, 500, Kerry_blue_terrier,17,16,300,482]                      |\n",
            "|[02100583, n02100583_702, 500, 333, vizsla,112,93,276,236]                                  |\n",
            "|[02109961, n02109961_1017, 475, 500, Eskimo_dog,43,20,472,461]                              |\n",
            "|[02096177, n02096177_11642, 500, 375, cairn,71,2,319,302]                                   |\n",
            "|[02108000, n02108000_3491, 600, 450, EntleBucher,307,94,515,448, EntleBucher,101,33,330,448]|\n",
            "|[02085782, n02085782_1731, 600, 449, Japanese_spaniel,23,0,598,435]                         |\n",
            "+--------------------------------------------------------------------------------------------+\n",
            "only showing top 15 rows\n",
            "\n",
            "Notice that the breed names start at index 4 onward.\n",
            "Some rows have more than one dog information. \n",
            "\n",
            "The final data look like this\n",
            "+--------+---------------+-----+------+--------------------+\n",
            "|  folder|       filename|width|height|            dog_list|\n",
            "+--------+---------------+-----+------+--------------------+\n",
            "|02110627|n02110627_12938|  200|   300|[affenpinscher,0,...|\n",
            "|02093754| n02093754_1148|  500|   378|[Border_terrier,7...|\n",
            "|      %s|             %s|  800|   600|[Shetland_sheepdo...|\n",
            "|02104029|   n02104029_63|  500|   375|[kuvasz,0,0,499,327]|\n",
            "|02111500| n02111500_5137|  500|   375|[Great_Pyrenees,1...|\n",
            "+--------+---------------+-----+------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Does the lambda version of udf return to same dataframe?: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiJtfiMPeNtJ",
        "outputId": "b13e06df-12ba-40f8-800f-38a9607da1ef"
      },
      "source": [
        "### Validate rows via join ###\r\n",
        "\r\n",
        "valid_folders_df = spark.read.csv(\"valid_folders.txt\")\r\n",
        "print(\"The valid folders data look like this: \")\r\n",
        "valid_folders_df.show(5)\r\n",
        "\r\n",
        "# Rename the column in valid_folders_df\r\n",
        "valid_folders_df = valid_folders_df.withColumnRenamed(\"_c0\", \"folder\")\r\n",
        "\r\n",
        "# Count the number of rows in split_df\r\n",
        "split_count = split_df.count()\r\n",
        "\r\n",
        "# Join the DataFrames\r\n",
        "joined_df = split_df.join(F.broadcast(valid_folders_df), \"folder\")\r\n",
        "\r\n",
        "# Compare the number of rows remaining\r\n",
        "joined_count = joined_df.count()\r\n",
        "print(\"Before: %d\\nAfter: %d\" % (split_count, joined_count))\r\n",
        "\r\n",
        "# Determine the row counts for each DataFrame\r\n",
        "split_count = split_df.count()\r\n",
        "joined_count = joined_df.count()\r\n",
        "\r\n",
        "# Create a DataFrame containing the invalid rows\r\n",
        "invalid_df = split_df.join(joined_df, on='folder', how='leftOuter')\r\n",
        "\r\n",
        "# Validate the count of the new DataFrame is as expected\r\n",
        "invalid_count = invalid_df.count()\r\n",
        "print(\" split_df:\\t%d\\n joined_df:\\t%d\\n invalid_df: \\t%d\" % (split_count, joined_count, invalid_count))\r\n",
        "\r\n",
        "# Determine the number of distinct folder rows removed\r\n",
        "invalid_folder_count = invalid_df.select('folder').distinct().count()\r\n",
        "print(\"%d distinct invalid folders found\" % invalid_folder_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The valid folders data look like this: \n",
            "+--------+\n",
            "|     _c0|\n",
            "+--------+\n",
            "|02085620|\n",
            "|02085782|\n",
            "|02085936|\n",
            "|02086079|\n",
            "|02086240|\n",
            "+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Before: 20580\n",
            "After: 19956\n",
            " split_df:\t20580\n",
            " joined_df:\t19956\n",
            " invalid_df: \t3496880\n",
            "117 distinct invalid folders found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VjEx3oRH6Zn",
        "outputId": "28d2ffe6-4a6a-4632-a28a-f1c989ba1a16"
      },
      "source": [
        "### Dog Parsing\r\n",
        "# Select the dog details and show 10 untruncated rows\r\n",
        "print(joined_df.select(\"dog_list\").show(10, truncate=False))\r\n",
        "\r\n",
        "# Define a schema type for the details in the dog list\r\n",
        "DogType = StructType([\r\n",
        "\tStructField(\"breed\", StringType(), False),\r\n",
        "    StructField(\"start_x\", IntegerType(), False),\r\n",
        "    StructField(\"start_y\", IntegerType(), False),\r\n",
        "    StructField(\"end_x\", IntegerType(), False),\r\n",
        "    StructField(\"end_y\", IntegerType(), False)])\r\n",
        "\r\n",
        "# Create a function to return the number and type of dogs as a tuple\r\n",
        "def dogParse(doglist):\r\n",
        "  dogs = []\r\n",
        "  for dog in doglist:\r\n",
        "    (breed, start_x, start_y, end_x, end_y) = dog.split(',')\r\n",
        "    dogs.append((breed, int(start_x), int(start_y), int(end_x), int(end_y)))\r\n",
        "  return dogs\r\n",
        "\r\n",
        "# Create a UDF\r\n",
        "udfDogParse = F.udf(dogParse, ArrayType(DogType))\r\n",
        "\r\n",
        "# Use the UDF to list of dogs and drop the old column\r\n",
        "joined_df = joined_df.withColumn('dogs', udfDogParse('dog_list')).drop('dog_list')\r\n",
        "\r\n",
        "# Show the number of dogs in the first 10 rows\r\n",
        "joined_df.select(F.size('dogs')).show(10)\r\n",
        "\r\n",
        "# Define a UDF to determine the number of pixels per image\r\n",
        "def dogPixelCount(doglist):\r\n",
        "  totalpixels = 0\r\n",
        "  for dog in doglist:\r\n",
        "    totalpixels += (dog[3] - dog[1]) * (dog[4] - dog[2])\r\n",
        "  return totalpixels\r\n",
        "\r\n",
        "# Define a UDF for the pixel count\r\n",
        "udfDogPixelCount = F.udf(dogPixelCount, IntegerType())\r\n",
        "joined_df = joined_df.withColumn(\"dog_pixels\", udfDogPixelCount(\"dogs\"))\r\n",
        "\r\n",
        "# Create a column representing the percentage of pixels\r\n",
        "joined_df = joined_df.withColumn('dog_percent', (joined_df[\"dog_pixels\"] / (joined_df[\"width\"]*joined_df[\"height\"])) * 100)\r\n",
        "\r\n",
        "# Show the first 10 annotations with more than 60% dog\r\n",
        "joined_df.filter(\"dog_percent > 60\").show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------------------------+\n",
            "|dog_list                          |\n",
            "+----------------------------------+\n",
            "|[affenpinscher,0,9,173,298]       |\n",
            "|[Border_terrier,73,127,341,335]   |\n",
            "|[kuvasz,0,0,499,327]              |\n",
            "|[Great_Pyrenees,124,225,403,374]  |\n",
            "|[schipperke,146,29,416,309]       |\n",
            "|[groenendael,168,0,469,374]       |\n",
            "|[Bedlington_terrier,10,12,462,332]|\n",
            "|[Lhasa,39,1,499,373]              |\n",
            "|[Kerry_blue_terrier,17,16,300,482]|\n",
            "|[vizsla,112,93,276,236]           |\n",
            "+----------------------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "None\n",
            "+----------+\n",
            "|size(dogs)|\n",
            "+----------+\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
            "|  folder|       filename|width|height|                dogs|dog_pixels|      dog_percent|\n",
            "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
            "|02110627|n02110627_12938|  200|   300|[[affenpinscher, ...|     49997|83.32833333333333|\n",
            "|02104029|   n02104029_63|  500|   375|[[kuvasz, 0, 0, 4...|    163173|          87.0256|\n",
            "|02105056| n02105056_2834|  500|   375|[[groenendael, 16...|    112574|60.03946666666666|\n",
            "|02093647|  n02093647_541|  500|   333|[[Bedlington_terr...|    144640|86.87087087087087|\n",
            "|02098413| n02098413_1355|  500|   375|[[Lhasa, 39, 1, 4...|    171120|           91.264|\n",
            "|02093859| n02093859_2309|  330|   500|[[Kerry_blue_terr...|    131878|79.92606060606062|\n",
            "|02109961| n02109961_1017|  475|   500|[[Eskimo_dog, 43,...|    189189|79.65852631578947|\n",
            "|02108000| n02108000_3491|  600|   450|[[EntleBucher, 30...|    168667|62.46925925925926|\n",
            "|02085782| n02085782_1731|  600|   449|[[Japanese_spanie...|    250125|92.84521158129176|\n",
            "|02110185| n02110185_2736|  259|   500|[[Siberian_husky,...|    113088|87.32664092664093|\n",
            "+--------+---------------+-----+------+--------------------+----------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZpSHVn-hf-r",
        "outputId": "98f9f88b-75b8-4f1a-bb7b-d85969ef7084"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|size(dogs)|\n",
            "+----------+\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "|         1|\n",
            "+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKzOT9s2iHZK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa3e9ee8-0084-4fcd-f5fc-ba2e82e17735"
      },
      "source": [
        "spark.version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.0.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDDa7J0NJvMX",
        "outputId": "89f5a28d-28d4-4e1c-801c-a8913ddaf84b"
      },
      "source": [
        "import sys; sys.version_info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aSzs-2vJ0Gd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}